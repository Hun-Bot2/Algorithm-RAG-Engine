# Cross-lingual Algorithm Retrieval: A Study on Semantic Alignment

## 1. 학습 목적
본 프로젝트는 서로 다른 언어(한국어, 영어)로 기술된 알고리즘 문제 간의 의미적 유사성을 측정하고, 이를 추천 시스템으로 연결하는 과정을 학습하기 위해 수행되었습니다.

### 1.1 핵심 문제 정의
* 한국어(Baekjoon)와 영어(LeetCode) 간의 도메인 갭(Domain Gap) 해소.
* 문장의 표면적 스타일이 아닌 알고리즘의 핵심을 기반으로 한 임베딩 정렬.
* 검색 재현율(Recall)과 정밀도(Precision)의 불균형을 해결하기 위한 파이프라인 최적화.

## 2. 데이터 엔지니어링 및 전처리
임베딩 모델이 문제의 문학적 묘사가 아닌 알고리즘의 핵심에 집중할 수 있도록 전처리 과정을 설계하였습니다.

### 2.1 핵심 정리
* HTML 태그 및 마크다운 특수 기호 제거.
* 핵심 로직, 제약 조건, 시간 및 공간 복잡도 패턴을 추출하여 요약문 형태로 변환.
* 데이터 대칭성 확보를 위해 백준과 리트코드의 접두사(Prefix)를 통일하는 Normalization 수행.

### 2.2 데이터셋 구성
* LeetCode: 3,500개 이상의 전수 데이터 확보.
* Baekjoon: 리트코드와 매핑 가능한 100개의 핵심 문제 선정.
* Ground Truth: 모델 평가를 위해 100세트의 BJ-LC 정답 쌍 구축.

## 3. 임베딩 모델 비교 분석 (Benchmarking)
교차 언어 검색 성능을 확인하기 위해 세 가지 주요 모델을 대상으로 성능을 측정하였습니다.

### 3.1 평가 지표 (Metrics)
* Recall@K: 상위 K개의 결과 중 정답이 포함된 비율.
* MRR (Mean Reciprocal Rank): 정답이 나타난 순위의 역수 평균.

### 3.2 벤치마크 결과 (100-Set Golden Set 기준)
| Model | Recall@1 | Recall@5 | Recall@10 | MRR |
| ----- | ----- | ----- | ----- | ----- |
| OpenAI-v3 (small) | 0.22 | 0.50 | 0.65 | 0.354 |
| Jina-v3 (1024 dim) | 0.17 | 0.47 | 0.63 | 0.319 |
| BGE-M3 (Local) | 0.15 | 0.40 | 0.53 | 0.272 |

**공학적 해석**: OpenAI-v3 모델이 다국어 의미 정렬에서 가장 우수하였으나, Recall@10(0.65) 대비 Recall@1(0.22)이 낮게 측정되었습니다. 이는 모델이 정답 후보군을 10위 안에는 잘 가져오지만(Search), 그중에서 최상위 1위를 결정짓는 변별력(Decision Power)이 부족함을 의미합니다.